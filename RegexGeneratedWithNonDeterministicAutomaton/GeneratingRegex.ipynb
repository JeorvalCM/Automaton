{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RegularExpressionGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NonDeterminsiticAutomaton:\n",
    "    \n",
    "    def __init__(self, q = None, sigma = None, delta = None, q0 = None, empty_symbol = \"lambda\",f = None):\n",
    "        \"\"\"\n",
    "        Class initializar\n",
    "        \n",
    "        self.q receives all the states that conform the dfa\n",
    "        \n",
    "        self.sigma are all the variables defined in the dfa\n",
    "        \n",
    "        self.delta all are the operation defined, i.e- is a dictionary contating a tuple as key\n",
    "        where the left values of the tuple is the current state and the right value the variable pass and the value obtain by\n",
    "        accessing to with the key is to which state goes.\n",
    "        \n",
    "        self.q0 is the initial state\n",
    "        \n",
    "        self.empty_symbol is the symbol in which is represent the empty value, for instance, it is lambda bout could be epsilon\n",
    "        or another symbol, but it has to be defined, it is not receive from txt.\n",
    "        \n",
    "        self.f are all the final states\n",
    "        \n",
    "        self.actual_state is the state which the dfa finish after proccessing a word, if no word proccess the actual state is q0\n",
    "        and it is reset at start proccessing a new word\n",
    "        \"\"\"\n",
    "        self.q = q\n",
    "        self.sigma = sigma\n",
    "        self.delta = delta\n",
    "        self.q0 = q0\n",
    "        self.empty_symbol = empty_symbol\n",
    "        self.f = f\n",
    "        self.actual_state = q0\n",
    "        \n",
    "        self.not_valid_actual_state = q0\n",
    "        \n",
    "        #private attributes\n",
    "        self.set_empty_transictions = []\n",
    "        \n",
    "        self.all_reacheble_states = set()\n",
    "        \n",
    "        self.valid_paths = []\n",
    "        \n",
    "        self.not_valid_paths = []\n",
    "        \n",
    "        #boolean to know if a word is accepted or not\n",
    "        self.trampa = False\n",
    "        \n",
    "        self.all_paths_for_a_symbol = []\n",
    "        \n",
    "        self.all_paths_empty_transitions = []\n",
    "        \n",
    "        \n",
    "    def load_from_file(self, path, delta_separator = \"-\"):\n",
    "        \"\"\"\n",
    "        Function to read a file that contains an automaton\n",
    "        \n",
    "        path: path file\n",
    "        \"\"\"\n",
    "        \n",
    "        #dictionary to save the parts of the automaton\n",
    "        variables = {\"q\": None,\n",
    "             \"sigma\": None,\n",
    "             \"delta\": None,\n",
    "             \"q0\": None,\n",
    "             \"f\": None    \n",
    "        }\n",
    "\n",
    "        with open(path) as file:\n",
    "            #parsing the document\n",
    "            for line, variable in zip(file, variables):\n",
    "                    line = line.replace(\"{\", \"\")\n",
    "                    line = line.replace(\"}\", \"\")\n",
    "                    line = line.replace(\"\\n\", \"\")\n",
    "                    line = line.replace(\" \", \"\")\n",
    "                    value = list(line.split(\",\"))\n",
    "                    variables[variable] = value\n",
    "                    \n",
    "            #conditional to verify there is only one initial state        \n",
    "            if len(variables[\"q0\"]) > 1 or len(variables[\"q0\"]) == 0:\n",
    "                raise Exception('There are more than one initial state')\n",
    "                \n",
    "            variables[\"delta\"] = [values.split(delta_separator) for values in variables[\"delta\"]]\n",
    "            \n",
    "            #Memory to check that within the transictions there is no variable with more than one variable\n",
    "            Memory = [True for value in variables[\"delta\"] if value[1] not in variables[\"sigma\"] and value[1] != self.empty_symbol]\n",
    "            \n",
    "            \n",
    "            if sum(Memory) >= 1:\n",
    "                # for example the language is {a, b} and the variable of that transiction is aa.\n",
    "                raise TypeError(\"At least One variable has a transiction with a variable that does not belong to sigma\")\n",
    "                \n",
    "            #creating all posible combination of each state with each symbol\n",
    "            all_possible_transictions = {(state,symbol): [\"z0_dead\"] for state in variables[\"q\"] for symbol in variables[\"sigma\"] }\n",
    "            \n",
    "            #creating transitions from the state of dead\n",
    "            for symbol in variables[\"sigma\"]:\n",
    "                 all_possible_transictions[(\"z0_dead\",symbol)] = [\"z0_dead\"]\n",
    "            \n",
    "            \n",
    "\n",
    "            #parsing\n",
    "            #getting the values from delta\n",
    "            for values in variables[\"delta\"]:\n",
    "                #creating the key\n",
    "                key = (values[0],values[1])\n",
    "                \n",
    "                #checking whether the key is \n",
    "                if key in all_possible_transictions.keys():\n",
    "                    #if the first variables is z0_dead, so that is the defaul creation and actually has transitions\n",
    "                    if all_possible_transictions[key][0] == \"z0_dead\":\n",
    "                        all_possible_transictions[key].pop()\n",
    "                        all_possible_transictions[key].append(values[2])\n",
    "                        \n",
    "                    else:\n",
    "                        all_possible_transictions[key].append(values[2])\n",
    "\n",
    "                else:\n",
    "                    all_possible_transictions[key] = [values[2]]\n",
    "                        \n",
    "             #getting q0\n",
    "            variables[\"q0\"] = variables[\"q0\"][0]\n",
    "            \n",
    "            #assigning the attributos of the class to the values obtained from the file\n",
    "            self.q = variables[\"q\"]\n",
    "            self.sigma = variables[\"sigma\"]\n",
    "            self.delta = all_possible_transictions\n",
    "            self.q0 = variables[\"q0\"] \n",
    "            self.f = variables[\"f\"]\n",
    "            self.actual_state = variables[\"q0\"]\n",
    "            \n",
    "            #conditional to verify the dfa is valid\n",
    "            if self.is_valid():\n",
    "                pass\n",
    "            else:\n",
    "                raise Exception('Is not a valid automaton')\n",
    "            \n",
    "            \n",
    "    \n",
    "    def empty_transitions(self, state, showing_backtracking = True):\n",
    "        \"\"\"\n",
    "        Function to find all reachable states from an initial state just passing empty symbols\n",
    "        \n",
    "        Input:\n",
    "        Current State\n",
    "        showing_backtracking: boolean to know whether to print the path or not\n",
    "        \n",
    "        Output:\n",
    "        return a list of all reachable state\n",
    "        \"\"\"\n",
    "        if set([state]).issubset(set(self.q)):\n",
    "            pass\n",
    "        else:\n",
    "            raise Exception(\"The given state does not belong to this automaton\")\n",
    "        \n",
    "        #reseting the set of empty transiction, this is a private attribute that is only useful in the methods of the classs\n",
    "        self.set_empty_transictions = set()\n",
    "        \n",
    "        #creating a list to save the backtracking\n",
    "        paths = [state]\n",
    "        \n",
    "        \n",
    "        self.empty_transitions_recursive(state, [state], paths, showing_backtracking) \n",
    "        \n",
    "        try:\n",
    "            #if exists, then discard it\n",
    "            self.set_empty_transictions.discard(\"z0_dead\")\n",
    "            return list(self.set_empty_transictions)\n",
    "            \n",
    "        except:                \n",
    "            return list(self.set_empty_transictions)\n",
    "        \n",
    "        \n",
    "        \n",
    "    def empty_transitions_recursive(self, state, memory = [], paths = [], showing_backtracking = True):\n",
    "        \"\"\"\n",
    "        Private Function to find all reachable states from an initial state just passing empty symbols, recursively\n",
    "        we did it in this way so we can get print the path, I mean for empty transitions, getting the paths may be\n",
    "        useless because it works for nothing but it seems neat xD.\n",
    "        \n",
    "        Input:\n",
    "        state: Current State\n",
    "        memory: is a list of states already visited by that path\n",
    "        showing_backtracking: boolean to know whether to print the path or not\n",
    "        \n",
    "        Output:\n",
    "        return a list of all reachable state\n",
    "        \"\"\"\n",
    "    \n",
    "        #memory to avoid infinite loops\n",
    "        memory_inside = memory[:]\n",
    "        \n",
    "        memory_inside.append(state)\n",
    "        \n",
    "        if showing_backtracking:\n",
    "            print(paths)\n",
    "        \n",
    "        #check if that transiction exists\n",
    "        try:\n",
    "            for new_state in self.delta[(state, self.empty_symbol)]:\n",
    "                #to avoid infinite loops\n",
    "                if new_state not in memory:\n",
    "                    #backtracking\n",
    "                    paths.append(new_state)\n",
    "                    \n",
    "                    #adding the new_state into that set\n",
    "                    self.set_empty_transictions.add(new_state)\n",
    "                    #recursion \n",
    "                    self.empty_transitions_recursive(new_state, memory_inside, paths, showing_backtracking)\n",
    "                    \n",
    "                    #eliminating the element, for backtracking\n",
    "                    paths.pop()\n",
    "                    \n",
    "                else:\n",
    "                    #when the infinite loop exist\n",
    "                    paths.append(new_state)\n",
    "                    \n",
    "                    if showing_backtracking:\n",
    "                        print(paths)\n",
    "                        \n",
    "                    #eliminating the element, for backtracking\n",
    "                    paths.pop()\n",
    "                    \n",
    "        except:\n",
    "            pass\n",
    "            \n",
    "        \n",
    "        \n",
    "        \n",
    "    def process_symbol(self, state, symbol, showing_backtracking = True):\n",
    "        \"\"\"\n",
    "        Function to find all the states you can reach from one state processing a symbol\n",
    "        \n",
    "        Input:\n",
    "        state: current state\n",
    "        \n",
    "        symbol: variable belonging to sigma\n",
    "        \n",
    "        showing_backtracking: boolean to know whether to print the path or not\n",
    "        \n",
    "        Output:\n",
    "        return a list of the reacheble states\n",
    "        \"\"\"\n",
    "        self.valid_string(symbol)\n",
    "        \n",
    "        if set([state]).issubset(set(self.q)):\n",
    "            pass\n",
    "        else:\n",
    "            raise Exception(\"The given state does not belong to this automaton\")\n",
    "        \n",
    "        #reseting attribute\n",
    "        self.all_paths_for_a_symbol = []\n",
    "        \n",
    "        #setting that set into the first reachable states\n",
    "        #First case where only consumes the symbol\n",
    "        self.all_reacheble_states  = set(self.delta[(state, symbol)])\n",
    "        \n",
    "        paths = [(state, symbol)]\n",
    "        \n",
    "        paths.append(self.delta[(state, symbol)])\n",
    "        if showing_backtracking:\n",
    "            print(\"-------------------------Case where reach a state only consuming the symbol-------------------------\")\n",
    "            print(paths)\n",
    "            \n",
    "        if self.delta[(state, symbol)] != []:\n",
    "            self.all_paths_for_a_symbol.append(paths[:])\n",
    "            \n",
    "        paths.pop()\n",
    "        \n",
    "        \n",
    "        #Second case where the symbol is consumed and then applyes lambda\n",
    "        \n",
    "        if showing_backtracking:\n",
    "            print(\"-------------------------Case where reach a state consuming the symbol and then lambda if possible-------------------------\")\n",
    "        \n",
    "        for new_state in self.delta[(state, symbol)]:\n",
    "            \n",
    "            if new_state != \"z0_dead\":\n",
    "                #adding the state and the symbol for transiction\n",
    "                paths.append((new_state, self.empty_symbol))\n",
    "                \n",
    "\n",
    "                #adding where it can reach after making that transiction\n",
    "                empty_transitions_list = self.empty_transitions(new_state, False)\n",
    "                \n",
    "                paths.append(empty_transitions_list)\n",
    "                \n",
    "                if empty_transitions_list != []:\n",
    "                    self.all_paths_for_a_symbol.append(paths[:])\n",
    "                if showing_backtracking:\n",
    "                    print(paths)\n",
    "\n",
    "                #uptading the set\n",
    "                self.all_reacheble_states.update(empty_transitions_list)\n",
    "                paths.pop()\n",
    "                paths.pop()\n",
    "        \n",
    "        \n",
    "        #third case first consumbes the empty symbol and then the synbol \n",
    "        #and also fourth case where consumes the empty symbol, then the symbol and again the empty symbol\n",
    "        #getting the transitions using lambda\n",
    "        new_reacheable_states = self.empty_transitions(state, False)\n",
    "        \n",
    "        \n",
    "        if showing_backtracking:\n",
    "            print(\"-------------------------Third and Fourth Case-------------------------\")\n",
    "        \n",
    "        paths = [(state, self.empty_symbol)]\n",
    "        \n",
    "        #going through the reacheable states using lambda and then the symbol\n",
    "        for new_state in new_reacheable_states:\n",
    "            \n",
    "            #saving the symbol and the symbol consume\n",
    "            paths.append((new_state, symbol))\n",
    "            #adding the reacheable states\n",
    "            paths.append(self.delta[(new_state, symbol)])\n",
    "            if showing_backtracking:\n",
    "                print(paths)\n",
    "    \n",
    "            self.all_reacheble_states.update(self.delta[(new_state, symbol)])\n",
    "            \n",
    "            self.all_paths_for_a_symbol.append(paths[:])\n",
    "            #eliminating those reachebale states because where are going to iterate, one by one\n",
    "            paths.pop()\n",
    "            \n",
    "            #going through the reacheable states using lambda, then the symbol and finally the empty transition\n",
    "            for second_next_state in self.delta[(new_state, symbol)]:\n",
    "                if second_next_state != \"z0_dead\":\n",
    "                    #saving the symbol and the symbol consume\n",
    "                    paths.append((second_next_state, self.empty_symbol))\n",
    "                    #adding the reacheable states\n",
    "                    \n",
    "                    empty_transitions_list = self.empty_transitions(second_next_state, False)\n",
    "                    \n",
    "                        \n",
    "                    paths.append(empty_transitions_list)\n",
    "                    if showing_backtracking:\n",
    "                        print(paths)\n",
    "                    \n",
    "                    if empty_transitions_list != []:\n",
    "                        self.all_paths_for_a_symbol.append(paths[:])\n",
    "    \n",
    "                    self.all_reacheble_states.update(empty_transitions_list)\n",
    "\n",
    "                    #eliminating for backtracking\n",
    "                    paths.pop()\n",
    "                    paths.pop()\n",
    "\n",
    "            #eliminating for backtracking    \n",
    "            paths.pop()\n",
    "            \n",
    "        lista_reacheable_state = list(self.all_reacheble_states)    \n",
    "            \n",
    "        if \"z0_dead\" in lista_reacheable_state:\n",
    "            lista_reacheable_state.append(lista_reacheable_state.pop(lista_reacheable_state.index(\"z0_dead\")))\n",
    "            \n",
    "        return lista_reacheable_state\n",
    "    \n",
    "    def process_word(self, word, showing_backtrack = True):\n",
    "        \"\"\"\n",
    "        Function to determine if a word belong to the language of the ndfa\n",
    "        \n",
    "        input:\n",
    "        Word: word to be proccessed\n",
    "        \n",
    "        Output:\n",
    "        return a bolean whether if the word is proccessed by the automaton or not\n",
    "        \"\"\" \n",
    "        self.valid_string(word)\n",
    "        \n",
    "        word = str(word)\n",
    "        \n",
    "        #reseting attributes\n",
    "        self.trampa = False\n",
    "\n",
    "        self.valid_paths = []\n",
    "\n",
    "        self.not_valid_paths = []\n",
    "\n",
    "        #memory\n",
    "        paths = []\n",
    "        \n",
    "        if word == \"\":\n",
    "            for state in self.empty_transitions(self.q0,False):\n",
    "                if state in self.f:\n",
    "                    self.trampa = True\n",
    "                    self.valid_paths.extend([(self.q0, self.empty_symbol), state])\n",
    "                    return self.trampa\n",
    "         \n",
    "        else:\n",
    "            \n",
    "            #going into recursive\n",
    "            self.process_word_recursive(word, self.q0 ,paths, showing_backtrack)\n",
    "\n",
    "            return self.trampa\n",
    "        \n",
    "    \n",
    "    def process_word_recursive(self, word, state,paths = [], showing_backtrack = True):\n",
    "        \"\"\"\n",
    "        Private method for the method process_word, in which it recursively goes to each possible paths to try to find a possible path \n",
    "        where the word is accepted\n",
    "        input:\n",
    "        Word: word to be proccessed\n",
    "        paths: list which is the memory for the backtracking\n",
    "        showing_backtrack: shows the backtracking or not\n",
    "        \n",
    "        Output:\n",
    "        return a bolean whether if the word is proccessed by the automaton or not\n",
    "        \"\"\"\n",
    "        #check if the word is not empty\n",
    "        try:\n",
    "            letter = word[0]\n",
    "        \n",
    "        #case where is no more variables to consume\n",
    "        except:\n",
    "            #checking if the last state is in final states\n",
    "            if state in list(self.f):\n",
    "                if showing_backtrack:\n",
    "                    print(\"---------------------------valid-----------------------\\n\\n\")\n",
    "                #saving that the word is valid   \n",
    "                self.trampa = True\n",
    "                #actul state to use in function str\n",
    "                self.actual_state = state\n",
    "                #saving the valid path\n",
    "                self.valid_paths.append(paths[:])\n",
    "                return \n",
    "            \n",
    "            #unvalid word\n",
    "            else:\n",
    "                if showing_backtrack:\n",
    "                    print(\"---------------------------Unvalid---------------------------\\n\\n\")\n",
    "                    #the same as the part latter\n",
    "                self.not_valid_actual_state = state\n",
    "                self.not_valid_paths.append(paths[:])\n",
    "                return\n",
    "        \n",
    "        #adding to the backtracking\n",
    "        paths.append((state,letter))\n",
    "        if showing_backtrack:\n",
    "            print(paths)\n",
    "        #going through each possible state with that letter\n",
    "        for possible_path in self.process_symbol(state, letter, False):\n",
    "            #saving for backtracking\n",
    "            paths.append(possible_path)\n",
    "            if showing_backtrack:\n",
    "                print(paths)\n",
    "                \n",
    "            #if it reaches the state of dead\n",
    "            if possible_path == \"z0_dead\":\n",
    "                if showing_backtrack:\n",
    "                    print(\"---------------------------Unvalid---------------------------\\n\\n\")\n",
    "                paths.pop()\n",
    "                paths.pop()\n",
    "                #you may think this should be a pass, but no because our  state of death, thank to the function process_symbol\n",
    "                # is always and the end of the list\n",
    "                return\n",
    "            \n",
    "            self.process_word_recursive(word[1:], possible_path, paths, showing_backtrack)\n",
    "            paths.pop()\n",
    "        paths.pop()\n",
    "        \n",
    "    def valid_string(self, word):\n",
    "        \n",
    "        if set(word).issubset(set(self.sigma)):\n",
    "            return\n",
    "        else:\n",
    "            raise Exception(\"Not valid word, contains variables that are not part of the language\")\n",
    "    \n",
    "        \n",
    "        \n",
    "    def __str__(self):\n",
    "        \n",
    "        if len(self.valid_paths) == 0:\n",
    "            self.actual_state = self.not_valid_actual_state\n",
    "        \n",
    "        cadena = \"Grammar: \\n q: {} \\n sigma: {}, delta: {}, q0: {}, f: {}, current_sate: {}, empty_symbol: {}\".format(\n",
    "                                                                                    self.q , \n",
    "                                                                                    self.sigma, \n",
    "                                                                                    self.delta, \n",
    "                                                                                    self.q0, \n",
    "                                                                                    self.f, \n",
    "                                                                                    self.actual_state,\n",
    "                                                                                    self.empty_symbol) \n",
    "        return cadena\n",
    "    \n",
    "    def is_valid(self):\n",
    "        \n",
    "        \"\"\"\n",
    "        Funtion to validate whether the dfa is valid or not\n",
    "        \n",
    "        Uses the attributes of the class\n",
    "        \"\"\"\n",
    "        \n",
    "        #gets the tuples which are the deltas defined\n",
    "        all_defined_oper = [(key1,key2)for key1, key2 in self.delta.keys() if key1 != \"z0_dead\"]\n",
    "        \n",
    "        #get the values of the deltas\n",
    "        all_to_go_states = [value for value in self.delta.values()]\n",
    "        \n",
    "        all_to_go_states = [item for sublist in all_to_go_states for item in sublist if item != \"z0_dead\"]\n",
    "        \n",
    "        #gets the left value of the tuple\n",
    "        all_states_to_receive = set([state[0] for state in list(self.delta.keys()) if state[0] != \"z0_dead\"])\n",
    "        \n",
    "        #gets the right value of the tuple\n",
    "        all_variables_to_receive = set([state[1] for state in list(self.delta.keys()) if state[0] != \"z0_dead\"])\n",
    "        \n",
    "        \n",
    "        #conditional to check if the final states are subsets of q, which is the variable containing all the states\n",
    "        if set(self.f).issubset(set(self.q)):\n",
    "            pass\n",
    "        \n",
    "        else:\n",
    "            raise TypeError(\"States of F are not a subset of states q\")\n",
    "            \n",
    "            \n",
    "        #conditional to check if the inital state is a subsets of q, which is the variable containing all the states    \n",
    "        if set([self.q0]).issubset(set(self.q)):\n",
    "            pass\n",
    "        \n",
    "        else:\n",
    "            raise TypeError(\"q0 is not a subset of states q\")\n",
    "            \n",
    "        \n",
    "        #checking if the left value of the tuple is subset of q and the right value is subset of sigma\n",
    "        if set(all_states_to_receive).issubset(set(self.q)):\n",
    "            pass\n",
    "        \n",
    "        else:\n",
    "            raise TypeError(\"The state before a applying the transiction is not a subset of q\")\n",
    "            \n",
    "        sigmas = set(self.sigma)\n",
    "        sigmas.add(self.empty_symbol)\n",
    "        if set(all_variables_to_receive).issubset(sigmas):\n",
    "            pass\n",
    "        \n",
    "        else:\n",
    "            print(all_variables_to_receive)\n",
    "            print(self.sigma)\n",
    "            raise TypeError(\"The variable which is apply to the transiction is not a subset of sigma\")\n",
    "        \n",
    "        #checking if all the transictions of delta are subsets of q\n",
    "        if set(all_to_go_states).issubset(set(self.q)):\n",
    "            pass\n",
    "        \n",
    "        else:\n",
    "            raise TypeError(\"The state resultant of a transiction is not a subset of states q\")\n",
    "            \n",
    "        return True\n",
    "    \n",
    "    def print_valid_path(self, path = None):\n",
    "        \"\"\"\n",
    "        Function to print one path of an accepted word, only works with valid paths, can be obtained using self.valid_paths\n",
    "        \n",
    "        input:\n",
    "        path: list that contains the path travelled\n",
    "        \n",
    "        output:\n",
    "        None\n",
    "        only prints the path\n",
    "        \"\"\"\n",
    "        # if the path is not defined, it gets the first path of valid_paths\n",
    "        if path == None:\n",
    "            path = self.valid_paths[0]\n",
    "            \n",
    "        #saving the paths\n",
    "        llaves = []\n",
    "        caminos = []\n",
    "        \n",
    "        #this division is used to avoid problems and make it easier to use because a valid path always has a pair number of elements+\n",
    "        #where the pair are a tuple of the transiction and the impairs is the resulf ot the tuple before\n",
    "        n = int(len(path)/2)\n",
    "        \n",
    "        #going through this list\n",
    "        for i in range(n):\n",
    "            #process the symbol of the right side of the tuple in the state that is in the left side of the same tuple\n",
    "            self.process_symbol(path[i*2][0],path[i*2][1], False)\n",
    "            \n",
    "            #going through each set of paths\n",
    "            for j in range(len(self.all_paths_for_a_symbol)):\n",
    "                #the list obtained in process symbol and saved in self.all_paths_for_a_symbol is made to each last element of the list within \n",
    "                #list are the states that reaches, so we get a path to reach that state consuming that symbol\n",
    "                if path[i*2 + 1] in self.all_paths_for_a_symbol[j][-1]:\n",
    "                    aux = self.all_paths_for_a_symbol[j]\n",
    "                    #saving the values\n",
    "                    llaves.append((path[i*2][0],path[i*2][1], path[i*2 + 1])) \n",
    "                    caminos.append(aux)\n",
    "                    break \n",
    "        \n",
    "        #we eliminate if there is more than one final state in the last element of the last list\n",
    "        for i in caminos[-1][-1]:\n",
    "            if i in self.f:\n",
    "                caminos[-1][-1] = [i]\n",
    "                break\n",
    "        \n",
    "        try:\n",
    "            #This code is to clean the paths adding the exact lambda transiction\n",
    "            n = len(caminos)\n",
    "            for path in range(n):\n",
    "                for trans in range(len(caminos[path])):\n",
    "                    #all the case before getting to the last element that always is an array\n",
    "                    if trans != len(caminos[path])-1:\n",
    "                        #case where the transiction is lambda\n",
    "                        if caminos[path][trans][1] == self.empty_symbol:\n",
    "                            #finding the path\n",
    "                            self.find_path(caminos[path][trans][0], caminos[path][trans+1][0])\n",
    "                            #case where the transiction is before the last element\n",
    "                            if trans == len(caminos[path])-2:\n",
    "                                caminos[path].pop(trans)\n",
    "                                caminos[path].pop(trans)\n",
    "                                #adding the transictions using lambda to get to the last element of the list\n",
    "                                for val in self.all_paths_empty_transitions[::-1]:\n",
    "                                        caminos[path].insert(trans, val)  \n",
    "                            #case where the element after the transictions is another tuple\n",
    "                            else:\n",
    "\n",
    "                                caminos[path].pop(trans)\n",
    "                                #adding the elements except the last one because is just a list, and is worthless\n",
    "                                for val in self.all_paths_empty_transitions[1::-1][1:]:\n",
    "                                        caminos[path].insert(trans, val) \n",
    "                                        \n",
    "            i = 1\n",
    "            #loops where the printins is made\n",
    "            j = 0\n",
    "            for values in list(caminos):\n",
    "                print(\"{}.- \".format(i), end = \"\")\n",
    "                for transition in range(len(values)):\n",
    "                    if transition < (len(values)-1):\n",
    "                        if len(values[transition+1]) > 1 and type(values[transition+1]) == list:\n",
    "                            for val in values[transition+1]:\n",
    "                                if j < len(caminos) - 1:\n",
    "                                    if val in caminos[j+1][0]:\n",
    "                                        print(\"{}  ======> {}---- \".format(values[transition],val), end = \"\")  \n",
    "                                else:\n",
    "                                    if val in self.f:\n",
    "                                        print(\"{}  ======> {}---- \".format(values[transition],val), end = \"\")\n",
    "                                        break\n",
    "                        else:\n",
    "                            print(\"{}  ======> {}---- \".format(values[transition],values[transition+1][0]), end = \"\")\n",
    "\n",
    "                    else:\n",
    "                        print()\n",
    "                j += 1\n",
    "                i += 1\n",
    "                            \n",
    "        except:\n",
    "            self.valid_paths = self.valid_paths[1:]\n",
    "            self.print_valid_path()\n",
    "            \n",
    "        \n",
    "    \n",
    "    def find_path(self, state, reach_state):\n",
    "        \"\"\"\n",
    "        Function to find a path from a state to other state using only lambda\n",
    "        \n",
    "        Input:\n",
    "        state: initial state\n",
    "        \n",
    "        reach_state: state where we want to reach\n",
    "        \n",
    "        Output: One possible path from the state to the reach_state using empty_symbols\n",
    "        \n",
    "        \"\"\"\n",
    "        self.all_paths_empty_transitions = []\n",
    "\n",
    "        self.__find_path(state, reach_state, memory = [], anti_loops = [])\n",
    "        \n",
    "        self.all_paths_empty_transitions = self.all_paths_empty_transitions[0]\n",
    "\n",
    "    def __find_path(self, state, reach_state, memory = [], anti_loops = []):\n",
    "        \"\"\"\n",
    "        Private function for find_path\n",
    "        Recursively gets all the paths from state to reach_state\n",
    "        \n",
    "        \"\"\"\n",
    "        anti_loops.append(state)\n",
    "        #case to finish recursivity\n",
    "        if state == reach_state:\n",
    "            memory.append([state])\n",
    "            self.all_paths_empty_transitions.append(memory[:])\n",
    "            return\n",
    "        else:\n",
    "            memory.append((state, self.empty_symbol))\n",
    "            try:\n",
    "                #checking if there is transiction with the empty_symbol\n",
    "                valores = self.delta[state,self.empty_symbol]\n",
    "                for estado in valores:\n",
    "                    if estado not in anti_loops:\n",
    "                        self.__find_path(estado, reach_state, memory, anti_loops)\n",
    "                    memory.pop()\n",
    "                    \n",
    "            except:\n",
    "                pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, copy\n",
    "\n",
    "class RegularExpressionGenerator(NonDeterminsiticAutomaton):\n",
    "    \n",
    "    def __init__(self, empty_symbol = \"lambda\"):\n",
    "        super().__init__(empty_symbol = empty_symbol)\n",
    "        \n",
    "        self.re_expressions = dict()\n",
    "        \n",
    "        self.re_compiler = dict()\n",
    "        \n",
    "        \"\"\"\n",
    "        Note the following attributes are not necessary because for educational porpouse allow us to see the initial of the automaton\n",
    "        and step by step how are pull together, however, they can be eliminated and the code does not seems affect, but the lines of code,\n",
    "        where those attributes appear have to be eliminated too. Since this is a educational porpouse we decided to not eliminate them but if \n",
    "        for the grade is necessary memory efficency, we can change it.\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        self.re_expressions_copy = dict()\n",
    "        \n",
    "        self.re_compiler_copy = dict()\n",
    "        \n",
    "        self.re_expressions_aux = dict()\n",
    "        \n",
    "        self.re_compiler_aux = dict()\n",
    "        \n",
    "        \n",
    "        #these attributes is necessary\n",
    "        self.remaining_states = []\n",
    "        \n",
    "        self.delta2 = dict()\n",
    "        \n",
    "    \n",
    "    def __create_new_start_final_state(self):\n",
    "        \"\"\"\n",
    "        Create the new initial state, connecting this one to the before initial state using the empty transition, and also creates a new final\n",
    "        state, and the previous final states are connected to this one using the empty transition\n",
    "        \"\"\"        \n",
    "        \n",
    "        self.delta2[(\"new_q0\",self.empty_symbol)] = [self.q0[:]]\n",
    "        \n",
    "        for state in self.f:\n",
    "            try:\n",
    "                self.delta2[(state,self.empty_symbol)].append(\"new_final\")\n",
    "                \n",
    "            except:\n",
    "                self.delta2[(state,self.empty_symbol)] = [\"new_final\"]\n",
    "                \n",
    "        \n",
    "    \n",
    "    def __initializing_re(self):\n",
    "        \"\"\"\n",
    "        Private method to initialie both re expression and re compile\n",
    "        \n",
    "        return or rather assigns the initial values for each re \n",
    "        \"\"\"\n",
    "        \n",
    "        for transiction in self.delta2:\n",
    "            for state in self.delta2[transiction]:\n",
    "                \n",
    "                #remember z0_dead is a state created by us, so in the reality is not part of the automaton\n",
    "                if state != \"z0_dead\" and transiction[0] != \"z0_dead\":\n",
    "                    if transiction[1] == self.empty_symbol:\n",
    "                        aux = \"λ\"\n",
    "\n",
    "                    else:\n",
    "                        aux = transiction[1]\n",
    "                        \n",
    "                    #parsing, if want to see what it does, check the attribute re_expressions_aux and re_compiler_aux\n",
    "                    try:\n",
    "                        tempor = self.re_compiler[(transiction[0], state)]\n",
    "                        if \"λ\" in tempor:\n",
    "                            self.re_compiler[(transiction[0], state)] = \"(\" + str(aux) + \")?\"\n",
    "                        \n",
    "                        elif \"λ\" in str(aux):\n",
    "                            if \"?\" in tempor:\n",
    "                                pass\n",
    "                            else:\n",
    "                                self.re_compiler[(transiction[0], state)] = \"(\" + tempor + \")?\"\n",
    "                        \n",
    "                        else:\n",
    "                            if \"?\" in self.re_compiler[(transiction[0], state)]:\n",
    "                                self.re_compiler[(transiction[0], state)] = self.re_compiler[(transiction[0], state)][1:-2] + str(aux) + \")?\"\n",
    "                            else:\n",
    "                                self.re_compiler[(transiction[0], state)] += \"|\"  + str(aux) \n",
    "\n",
    "                        self.re_expressions[(transiction[0], state)] += \" U \" + str(aux)\n",
    "\n",
    "                    except:\n",
    "                        self.re_compiler[(transiction[0], state)] =  str(aux) \n",
    "\n",
    "                        self.re_expressions[(transiction[0], state)] = str(aux)\n",
    "                        \n",
    "\n",
    "                \n",
    "    \n",
    "    def __in_out_lists(self, state, in_list = [], out_list = []):\n",
    "        \"\"\"\n",
    "        Function to create the list in and out, in are the states that can get to the given state and out is the states reacheables by that\n",
    "        state\n",
    "        \n",
    "        Input:\n",
    "        state: state is needed the in and out lists\n",
    "        in_list: list where to save the values for the in states\n",
    "        out_list: list where to sabe the values for the out states\n",
    "        \n",
    "        Output:\n",
    "        return in_list and out_list\n",
    "        \"\"\"\n",
    "        for transiction in self.re_expressions:\n",
    "            if transiction[0] == state and transiction[1] != state:\n",
    "                out_list.append(transiction[1])\n",
    "                \n",
    "            elif transiction[1] == state and transiction[0] !=state:\n",
    "                in_list.append(transiction[0])\n",
    "    \n",
    "    def __permutation(self, list1 = [], list2 = []):\n",
    "        \"\"\"\n",
    "        Function to create all the combinations between all the values of two given lists\n",
    "        \n",
    "        input:\n",
    "        list1: list \n",
    "        list2: list\n",
    "        \n",
    "        output:\n",
    "        return a list containing the combinations of both lists\n",
    "        \"\"\"\n",
    "        combination = []\n",
    "        \n",
    "        for i in list1:\n",
    "            for j in list2:\n",
    "                combination.append((i,j))\n",
    "        \n",
    "        return combination\n",
    "    \n",
    "    \n",
    "    def __eliminate_key(self, state):\n",
    "        \"\"\"\n",
    "        Function to eliminate garbage values given a state\n",
    "        \n",
    "        Input:\n",
    "        state to eliminate the key and the values in the dictionary\n",
    "        \"\"\"\n",
    "        aux = self.re_expressions.copy()\n",
    "        for states in aux:\n",
    "            if state == states[0] or state == states[1]:\n",
    "                self.re_expressions.pop(states, None)\n",
    "                \n",
    "        aux = self.re_compiler.copy()\n",
    "        \n",
    "        for states in aux:\n",
    "            if state == states[0] or state == states[1]:\n",
    "                self.re_compiler.pop(states, None)\n",
    "    \n",
    "    def convert_automaton(self):\n",
    "        \"\"\"\n",
    "        Function to get the regular expression seen in class, and the regular expression for the re python library\n",
    "        \n",
    "        return those re expression\n",
    "        \n",
    "        \"\"\"\n",
    "        #copy of delta\n",
    "        self.delta2 = copy.deepcopy(self.delta)\n",
    "        \n",
    "        #creating the new and final states\n",
    "        self.__create_new_start_final_state()\n",
    "        \n",
    "        #initilazing the re dictionaries\n",
    "        self.__initializing_re()\n",
    "        \n",
    "        self.re_expressions_copy = copy.deepcopy(self.re_expressions)\n",
    "        \n",
    "        self.re_expressions_aux = copy.deepcopy(self.re_expressions)\n",
    "        \n",
    "        self.re_compiler_copy = copy.deepcopy(self.re_compiler)\n",
    "        \n",
    "        self.re_compiler_aux = copy.deepcopy(self.re_compiler)\n",
    "        \n",
    "        #loop to go through all the states of the automata\n",
    "        for state in self.q:\n",
    "            #initializing and reseting the in and out list\n",
    "            in_list = []\n",
    "            out_list = []\n",
    "            \n",
    "                \n",
    "            #creating the in and out lists\n",
    "            self.__in_out_lists(state, in_list, out_list)\n",
    "\n",
    "            #creating the combinations of those states\n",
    "            combinations = self.__permutation(in_list, out_list)\n",
    "\n",
    "            #going through each comb\n",
    "            for comb in combinations:\n",
    "\n",
    "                \"\"\"\n",
    "                Part for regular expression\n",
    "                \"\"\"\n",
    "\n",
    "                aux1 = self.re_expressions[(comb[0],state)]\n",
    "                aux2 = self.re_expressions[(state, comb[1])]\n",
    "\n",
    "                \"\"\"\n",
    "                All the following code all the if, elif, try and excepts is just to give that neat format\n",
    "                \"\"\"\n",
    "                if len(aux1) > 1 and \"(\" not in aux1 and \"U\" in aux1:\n",
    "                    aux1 = \"(\" + aux1 + \")\"\n",
    "\n",
    "                if len(aux2) > 1 and \"(\" not in aux2 and \"U\" in aux2:\n",
    "                    aux2 = \"(\" + aux2 + \")\"\n",
    "\n",
    "\n",
    "                #checking if the current state has a transiction to itself\n",
    "                try:\n",
    "                    temp = self.re_expressions[(state,state)]\n",
    "\n",
    "                    #case where it has already the parenthesis\n",
    "                    if temp[0] == \"(\" and temp[-1] == \")\":\n",
    "                        aux3 = temp + \"*\"\n",
    "\n",
    "                    else:\n",
    "                        aux3 = \"(\" + temp + \")*\"\n",
    "\n",
    "                #if not is empty\n",
    "                except:\n",
    "                    aux3 = \"\"\n",
    "\n",
    "                #the try is to check if the key already exists\n",
    "                if comb in self.re_expressions:\n",
    "                    #case where the state has a transiction to itself\n",
    "                    if aux3 != \"\":\n",
    "                        self.re_expressions[comb] = \"(\"+self.re_expressions[comb]+\" U \"+\"(\"+aux1 + \".\" + aux3 + \".\" + aux2 + \")\" +\")\"\n",
    "                        self.re_expressions_copy[comb] = self.re_expressions[comb]\n",
    "\n",
    "                    else:\n",
    "                        self.re_expressions[comb] = \"(\" + self.re_expressions[comb] + \" U \" + aux1 + \".\" + aux2 + \")\"\n",
    "                        self.re_expressions_copy[comb] = self.re_expressions[comb]\n",
    "\n",
    "                else:\n",
    "\n",
    "                    #case where the state has a transiction to itself\n",
    "                    if aux3 != \"\": \n",
    "                        if aux1 == \"λ\" and aux2 == \"λ\" and aux3 != \"(λ)*\":\n",
    "                            self.re_expressions[comb] = aux3\n",
    "                            self.re_expressions_copy[comb] = self.re_expressions[comb]\n",
    "\n",
    "                        elif aux1 == \"λ\" and aux2 != \"λ\" and  aux3 != \"(λ)*\":\n",
    "                            self.re_expressions[comb] = aux3 +  \".\" + aux2 \n",
    "                            self.re_expressions_copy[comb] = self.re_expressions[comb]\n",
    "\n",
    "                        elif aux2 == \"λ\" and aux1 != \"λ\" and  aux3 != \"(λ)*\":\n",
    "                            self.re_expressions[comb] = aux1 + \".\" + aux3 \n",
    "                            self.re_expressions_copy[comb] = self.re_expressions[comb]\n",
    "\n",
    "                        elif aux3 == \"(λ)*\" and aux1 == \"λ\" and aux2 == \"λ\":\n",
    "                            self.re_expressions[comb] = \"λ\"\n",
    "                            self.re_expressions_copy[comb] = self.re_expressions[comb]\n",
    "\n",
    "                        elif aux3 == \"(λ)*\" and aux1 == \"λ\" and aux2 != \"λ\":\n",
    "                            self.re_expressions[comb] = aux2\n",
    "                            self.re_expressions_copy[comb] = self.re_expressions[comb]\n",
    "\n",
    "                        elif aux3 == \"(λ)*\" and aux1 != \"λ\" and aux2 == \"λ\":\n",
    "                            self.re_expressions[comb] = aux1 \n",
    "                            self.re_expressions_copy[comb] = self.re_expressions[comb]\n",
    "\n",
    "                        elif aux3 == \"(λ)*\" and aux1 != \"λ\" and aux2 != \"λ\":\n",
    "                            self.re_expressions[comb] = aux1 + \".\" + aux2\n",
    "                            self.re_expressions_copy[comb] = self.re_expressions[comb]\n",
    "\n",
    "                        else:\n",
    "                            self.re_expressions[comb] = aux1 + \".\" + aux3 +  \".\" + aux2\n",
    "                            self.re_expressions_copy[comb] = self.re_expressions[comb]\n",
    "                    else:\n",
    "\n",
    "                        if aux1 == \"λ\" and aux2 == \"λ\":\n",
    "                            self.re_expressions[comb] = \"λ\" \n",
    "                            self.re_expressions_copy[comb] = self.re_expressions[comb]\n",
    "\n",
    "                        elif aux1 == \"λ\" and aux2 != \"λ\":\n",
    "                            self.re_expressions[comb] = aux2 \n",
    "                            self.re_expressions_copy[comb] = self.re_expressions[comb]\n",
    "\n",
    "                        elif aux2 == \"λ\" and aux1 != \"λ\":\n",
    "                            self.re_expressions[comb] = aux1\n",
    "                            self.re_expressions_copy[comb] = self.re_expressions[comb]\n",
    "\n",
    "                        else:\n",
    "                            self.re_expressions[comb] = aux1 + \".\" + aux2\n",
    "                            self.re_expressions_copy[comb] = self.re_expressions[comb]\n",
    "\n",
    "                \"\"\"\n",
    "                Part for the expression for the re library\n",
    "                \"\"\"\n",
    "                aux1 = self.re_compiler[(comb[0],state)]\n",
    "                aux2 = self.re_compiler[(state, comb[1])]\n",
    "\n",
    "                if len(aux1) > 1 and \"(\" not in aux1 and \"|\" in aux1:\n",
    "                    aux1 = \"(\" + aux1 + \")\"\n",
    "\n",
    "                if len(aux2) > 1 and \"(\" not in aux2 and \"|\" in aux2:\n",
    "                    aux2 = \"(\" + aux2 + \")\"\n",
    "                    \n",
    "                if aux1 == \"λ\":\n",
    "                    aux1 = \"\"\n",
    "\n",
    "                if aux2 == \"λ\":\n",
    "                    aux2 = \"\"\n",
    "\n",
    "                #try to check if the state has a transiction to itself\n",
    "                try:\n",
    "                    temp = self.re_compiler[(state,state)]\n",
    "                    \n",
    "                    aux3 = temp + \"*\"\n",
    "\n",
    "                    #if temp[0] == \"(\" and temp[-1] == \")\":\n",
    "                     #   aux3 = temp + \"*\"\n",
    "                    #else:\n",
    "                     #   aux3 = \"(\" + temp + \")*\"\n",
    "\n",
    "                except:\n",
    "                    aux3 = \"\"\n",
    "\n",
    "                #try to check if exist the key comb\n",
    "                if comb in self.re_compiler:\n",
    "                    #exist a transiction to itself\n",
    "                    if aux3 != \"\":\n",
    "                        tempor = self.re_compiler[comb]\n",
    "\n",
    "                        if tempor == \"\":\n",
    "                            if aux1 == \"\" and aux3 == \"\" and aux2 == \"\":\n",
    "                                self.re_compiler[comb] =  \"\"\n",
    "                                self.re_compiler_copy[comb] = self.re_compiler[comb]\n",
    "\n",
    "                            else:\n",
    "                                self.re_compiler[comb] =  \"(\" + aux1 + aux3 + aux2 + \")?\"\n",
    "                                self.re_compiler_copy[comb] = self.re_compiler[comb]\n",
    "\n",
    "                        elif aux1 == \"\":\n",
    "                            if aux3 == \"\" and aux2 == \"\":\n",
    "                                self.re_compiler[comb] = self.re_compiler[comb]\n",
    "                                self.re_compiler_copy[comb] = self.re_compiler[comb]\n",
    "\n",
    "                            else:\n",
    "                                self.re_compiler[comb] = \"(\" + self.re_compiler[comb] +\"|\" + \"(\" + aux3 + aux2 + \")\" + \")\"\n",
    "                                self.re_compiler_copy[comb] = self.re_compiler[comb]\n",
    "\n",
    "                        elif aux2 == \"\":\n",
    "                            if aux1 == \"\" and aux3 == \"\":\n",
    "                                self.re_compiler[comb] = self.re_compiler[comb]\n",
    "                                self.re_compiler_copy[comb] = self.re_compiler[comb]\n",
    "\n",
    "                            else:\n",
    "                                self.re_compiler[comb] = \"(\" + self.re_compiler[comb] +\"|\" + \"(\" + aux1 + aux3 + \")\" + \")\"\n",
    "                                self.re_compiler_copy[comb] = self.re_compiler[comb]\n",
    "\n",
    "                        elif aux3 == \"\":\n",
    "                            if aux1 == \"\" and aux2 == \"\":\n",
    "                                self.re_compiler[comb] = self.re_compiler[comb]\n",
    "                                self.re_compiler_copy[comb] = self.re_compiler[comb]\n",
    "\n",
    "                            else:\n",
    "                                self.re_compiler[comb] = \"(\" + self.re_compiler[comb] +\"|\" + \"(\" + aux1 + aux2 + \")\" + \")\"\n",
    "                                self.re_compiler_copy[comb] = self.re_compiler[comb]\n",
    "\n",
    "                        else:\n",
    "                            if aux1 == \"\" and aux2 == \"\" and aux3 == \"\":\n",
    "                                self.re_compiler[comb] = \"(\" + self.re_compiler[comb] +\"|\" + \"(\" + aux1 + aux3 + aux2 + \")\" + \")\"\n",
    "                                self.re_compiler_copy[comb] = self.re_compiler[comb]\n",
    "\n",
    "                            else:\n",
    "                                self.re_compiler[comb] = \"(\" + self.re_compiler[comb] +\"|\" + \"(\" + aux1 + aux3 + aux2 + \")\" + \")\"\n",
    "                                self.re_compiler_copy[comb] = self.re_compiler[comb]\n",
    "\n",
    "                    #there no exists transiction to itself\n",
    "                    else:\n",
    "                        tempor = self.re_compiler[comb]\n",
    "                        if tempor == \"\":\n",
    "                            if aux1 == \"\" and aux2 == \"\":\n",
    "                                self.re_compiler[comb] = \"\"\n",
    "                                self.re_compiler_copy[comb] = self.re_compiler[comb]\n",
    "\n",
    "\n",
    "                            else:\n",
    "                                self.re_compiler[comb] = \"(\" + aux1 + aux2 + \")?\"\n",
    "                                self.re_compiler_copy[comb] = self.re_compiler[comb]\n",
    "\n",
    "                        elif aux1 == \"\":\n",
    "                            if aux2 == \"\":\n",
    "                                self.re_compiler[comb] = self.re_compiler[comb]\n",
    "                                self.re_compiler_copy[comb] = self.re_compiler[comb]\n",
    "\n",
    "                            else:\n",
    "                                self.re_compiler[comb] = \"(\" + self.re_compiler[comb] + \"|\" + aux2 + \")\"\n",
    "                                self.re_compiler_copy[comb] = self.re_compiler[comb]\n",
    "\n",
    "                        elif aux2 == \"\":\n",
    "                            if aux1 == \"\":\n",
    "                                self.re_compiler[comb] = self.re_compiler[comb]\n",
    "                                self.re_compiler_copy[comb] = self.re_compiler[comb]\n",
    "\n",
    "                            else:\n",
    "                                self.re_compiler[comb] = \"(\" + self.re_compiler[comb] + \"|\" + aux1 + \")\" \n",
    "                                self.re_compiler_copy[comb] = self.re_compiler[comb]\n",
    "                                    \n",
    "                        else:    \n",
    "                            if aux1 == \"\" and aux2 == \"\":\n",
    "                                self.re_compiler[comb] = self.re_compiler[comb]\n",
    "                                self.re_compiler_copy[comb] = self.re_compiler[comb]\n",
    "\n",
    "                            else:\n",
    "                                self.re_compiler[comb] = \"(\" + self.re_compiler[comb] + \"|\" + \"(\" +aux1 + aux2 + \")\" + \")\"\n",
    "                                self.re_compiler_copy[comb] = self.recompiler[comb]\n",
    "\n",
    "                else:\n",
    "                    #exist a transiction to itself\n",
    "                    if aux3 != \"\": \n",
    "                        if aux1 == \"λ\":\n",
    "                            aux1 = \"\"\n",
    "\n",
    "                        if aux2 == \"λ\":\n",
    "                            aux2 = \"\"\n",
    "\n",
    "                        if aux3 == \"(λ)*\":\n",
    "                            aux3 = \"\"\n",
    "\n",
    "\n",
    "                        if aux1 == \"\" and aux2 == \"\" and aux3 == \"\":\n",
    "                            self.re_compiler[comb] = \"\"\n",
    "                            self.re_compiler_copy[comb] = self.re_compiler[comb]\n",
    "\n",
    "                        else:\n",
    "                            if aux1 != \"\" and aux2 == \"\" and aux3 == \"\":\n",
    "                                self.re_compiler[comb] = aux1\n",
    "                                self.re_compiler_copy[comb] = self.re_compiler[comb]\n",
    "\n",
    "                            elif aux1 == \"\" and aux2 != \"\" and aux3 == \"\":\n",
    "                                self.re_compiler[comb] = aux2\n",
    "                                self.re_compiler_copy[comb] = self.re_compiler[comb]\n",
    "\n",
    "                            elif aux1 == \"\" and aux2 == \"\" and aux3 != \"\":\n",
    "                                self.re_compiler[comb] = aux3\n",
    "                                self.re_compiler_copy[comb] = self.re_compiler[comb]\n",
    "                            else:\n",
    "                                self.re_compiler[comb] = \"(\" + aux1 + aux3 + aux2 + \")\"\n",
    "                                self.re_compiler_copy[comb] = self.re_compiler[comb]\n",
    "\n",
    "                    #there no exists transiction to itself\n",
    "                    else:\n",
    "                        if aux1 == \"λ\":\n",
    "                            aux1 = \"\"\n",
    "\n",
    "                        if aux2 == \"λ\":\n",
    "                            aux2 = \"\"\n",
    "\n",
    "                        if aux1 == \"\" and aux2 == \"\":\n",
    "                            self.re_compiler[comb] = \"\"\n",
    "                            self.re_compiler_copy[comb] = self.re_compiler[comb]\n",
    "\n",
    "                        else:\n",
    "                            if aux1 == \"\":\n",
    "                                self.re_compiler[comb] = aux2\n",
    "                                self.re_compiler_copy[comb] = self.re_compiler[comb]  \n",
    "\n",
    "                            elif aux2 == \"\":\n",
    "                                self.re_compiler[comb] = aux1\n",
    "                                self.re_compiler_copy[comb] = self.re_compiler[comb]  \n",
    "\n",
    "                            else:\n",
    "                                self.re_compiler[comb] = \"(\" + aux1 + aux2 + \")\"\n",
    "                                self.re_compiler_copy[comb] = self.re_compiler[comb]  \n",
    "\n",
    "\n",
    "\n",
    "            self.__eliminate_key(state)\n",
    "                \n",
    "                \n",
    "    def check_word(self, string, printing = True):\n",
    "        \"\"\"\n",
    "        Function to find all matches of the expression in the string.\n",
    "        \n",
    "        Input:\n",
    "        given string to find the matches\n",
    "        \n",
    "        Output:\n",
    "        return all matches of the expression in the string\n",
    "        \"\"\"\n",
    "        \n",
    "        ans = []\n",
    "        exist_lambda = False\n",
    "        \n",
    "        #checking if the state can reach the final state being an empty string or \"\"\n",
    "        for state in self.empty_transitions(self.q0,False):\n",
    "            if state in self.f:\n",
    "                exist_lambda = True\n",
    "                break\n",
    "        \n",
    "        #checking if the convert automaton is already run\n",
    "        if ('new_q0', 'new_final') in self.re_compiler:\n",
    "            \n",
    "            #getting the pattern\n",
    "            pattern = self.re_compiler[('new_q0', 'new_final')]\n",
    "\n",
    "            match = re.findall(pattern, string)\n",
    "            for match in re.finditer(pattern, string):\n",
    "                if match.group() == \"\":\n",
    "                    #case where the \"\" is accepted in the automaton\n",
    "                    if exist_lambda:\n",
    "                        \n",
    "                        if printing: print(match.group())\n",
    "                        ans.append(match.group())\n",
    "                        \n",
    "                    else:\n",
    "                        pass\n",
    "                        \n",
    "                else:\n",
    "                    if printing: print(match.group())\n",
    "                    ans.append(match.group())\n",
    "        \n",
    "        #case where convert automaton have not been run\n",
    "        else:\n",
    "            \n",
    "            self.convert_automaton()\n",
    "            \n",
    "            try:\n",
    "                pattern = self.re_compiler[('new_q0', 'new_final')]\n",
    "                \n",
    "            except:\n",
    "                raise Exception(\"This automata its final states are not reacheable, so there is not a regular expression\")\n",
    "\n",
    "            match = re.findall(pattern, string)\n",
    "            for match in re.finditer(pattern, string):\n",
    "                if match.group() == \"\":\n",
    "                    #case where the \"\" is accepted in the automaton\n",
    "                    if exist_lambda:\n",
    "                        print(match.group())\n",
    "                        ans.append(match.group())\n",
    "                        \n",
    "                    else:\n",
    "                        pass\n",
    "                        \n",
    "                else:\n",
    "                    print(match.group())\n",
    "                    ans.append(match.group())\n",
    "                \n",
    "        return ans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code explanation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we have gone through the explanation of NonDeterminsiticAutomaton, we are not going to go into its methods, we are only going to focus on the methods of the new class class RegularExpressionGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Private Method: __create_new_start_final_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "def __create_new_start_final_state(self):\n",
    "\n",
    "        self.delta2[(\"new_q0\",self.empty_symbol)] = [self.q0[:]]\n",
    "        \n",
    "        for state in self.f:\n",
    "            try:\n",
    "                self.delta2[(state,self.empty_symbol)].append(\"new_final\")\n",
    "                \n",
    "            except:\n",
    "                self.delta2[(state,self.empty_symbol)] = [\"new_final\"]\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As its name says, this function create the new initial state which is connected to the prior initial state using an empty transition, and creates the final states which is reached by all the previous final states using an empty transition. And the function also add the respectives transition for those new states to reach the void state "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Private Method: __initializing_re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "def __initializing_re(self):\n",
    "        \n",
    "        for transiction in self.delta2:\n",
    "            for state in self.delta2[transiction]:\n",
    "                \n",
    "                if state != \"z0_dead\" and transiction[0] != \"z0_dead\":\n",
    "                    if transiction[1] == self.empty_symbol:\n",
    "                        aux = \"λ\"\n",
    "\n",
    "                    else:\n",
    "                        aux = transiction[1]\n",
    "                        \n",
    "                    try:\n",
    "                        tempor = self.re_compiler[(transiction[0], state)]\n",
    "                        if \"λ\" in tempor:\n",
    "                            self.re_compiler[(transiction[0], state)] = \"(\" + str(aux) + \")?\"\n",
    "                        \n",
    "                        elif \"λ\" in str(aux):\n",
    "                            self.re_compiler[(transiction[0], state)] = \"(\" + tempor + \")?\"\n",
    "                        \n",
    "                        else:\n",
    "                            self.re_compiler[(transiction[0], state)] += \"|\"  + str(aux) \n",
    "\n",
    "                        self.re_expressions[(transiction[0], state)] += \" U \" + str(aux)\n",
    "\n",
    "                    except:\n",
    "                        self.re_compiler[(transiction[0], state)] =  str(aux) \n",
    "\n",
    "                        self.re_expressions[(transiction[0], state)] = str(aux)\n",
    "                        \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__initialiing_re what it does is to create the first instances for both the re (python library) expression and the regular expression (terms seen in class), it makes a litle change the keys are the two connected states, the left state is the input state and the right the output state, so the values of the key are the actual expressions for that transaction.\n",
    "\n",
    "For example, we have the transicionts (\"q0\",\"1\") = q1 and (\"q0\",\"0\") = q1, this becomes\n",
    "\n",
    "(\"q0\",\"q1\") = 0 U 1, for regular expression and (\"q0\",\"q1\") = 0 | 1, for re compiler\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Private method in_out_lists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "def __in_out_lists(self, state, in_list = [], out_list = []):\n",
    "\n",
    "        for transiction in self.re_expressions:\n",
    "            if transiction[0] == state and transiction[1] != state:\n",
    "                out_list.append(transiction[1])\n",
    "                \n",
    "            elif transiction[1] == state and transiction[0] !=state:\n",
    "                in_list.append(transiction[0])\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function gets a list of all the states that can reach a given state , in_list, and gets a list of all the reacheable states for a given state, out_list."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Private method permutation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "def __permutation(self, list1 = [], list2 = []):\n",
    "        combination = []\n",
    "        \n",
    "        for i in list1:\n",
    "            for j in list2:\n",
    "                combination.append((i,j))\n",
    "        \n",
    "        return combination\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function gets all the possible pair combinations between each elements of two given lists:\n",
    "\n",
    "Example given the lists [1,2,3] and [4,5].\n",
    "\n",
    "It will return [(1,4),(1,5), (2,4), (2,5), (3,4) , (4,5)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Private method eliminate_key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "def __eliminate_key(self, state):\n",
    "        aux = self.re_expressions.copy()\n",
    "        for states in aux:\n",
    "            if state == states[0] or state == states[1]:\n",
    "                self.re_expressions.pop(states, None)\n",
    "                \n",
    "        aux = self.re_compiler.copy()\n",
    "        \n",
    "        for states in aux:\n",
    "            if state == states[0] or state == states[1]:\n",
    "                self.re_compiler.pop(states, None)\n",
    "                \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function eliminates all the transiction in both re_expressions and re_compiler of a given states, this state is already used, therefore, having it still in the transiction makes an overlap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Private method check_word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "def check_word(self, string):        \n",
    "        if ('new_q0', 'new_final') in self.re_compiler:\n",
    "            \n",
    "        \n",
    "            pattern = self.re_compiler[('new_q0', 'new_final')]\n",
    "\n",
    "            match = re.findall(pattern, string)\n",
    "            for match in re.finditer(pattern, string):\n",
    "                print(match.group())\n",
    "        else:\n",
    "            \n",
    "            self.convert_automaton()\n",
    "            \n",
    "            pattern = self.re_compiler[('new_q0', 'new_final')]\n",
    "\n",
    "            match = re.findall(pattern, string)\n",
    "            for match in re.finditer(pattern, string):\n",
    "                print(match.group())\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function gets all the matchs on a string of the re expression of the automaton"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note: The function convert_automaton we consider is well explained in the code comments and even though contains a lot of try - except and if - else, is not that complicated because that is to only give it format. And the method is understandable by its own."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndfa = RegularExpressionGenerator(empty_symbol = \"lambda\")\n",
    "ndfa.load_from_file(\"automaton_examples/automata.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndfa.convert_automaton()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('q0', 'q3'): '0',\n",
       " ('q0', 'q1'): '0',\n",
       " ('q1', 'q2'): '0',\n",
       " ('q1', 'q1'): '1',\n",
       " ('q2', 'q2'): '0',\n",
       " ('q2', 'q1'): '(1)?',\n",
       " ('q3', 'q3'): '0',\n",
       " ('q0', 'q2'): 'λ',\n",
       " ('q2', 'new_final'): 'λ',\n",
       " ('new_q0', 'q0'): 'λ'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ndfa.re_compiler_aux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('q0', 'q3'): '0',\n",
       " ('q0', 'q1'): '0',\n",
       " ('q1', 'q2'): '0',\n",
       " ('q1', 'q1'): '1',\n",
       " ('q2', 'q2'): '(0|((1)?1*0))',\n",
       " ('q2', 'q1'): '(1)?',\n",
       " ('q3', 'q3'): '0',\n",
       " ('q0', 'q2'): 'λ',\n",
       " ('q2', 'new_final'): 'λ',\n",
       " ('new_q0', 'q0'): 'λ',\n",
       " ('new_q0', 'q3'): '0',\n",
       " ('new_q0', 'q1'): '0',\n",
       " ('new_q0', 'q2'): '(01*0)?',\n",
       " ('new_q0', 'new_final'): '((01*0)?(0|((1)?1*0))*)'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ndfa.re_compiler_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('new_q0', 'new_final'): '((01*0)?(0|((1)?1*0))*)'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ndfa.re_compiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('q0', 'q3'): '0',\n",
       " ('q0', 'q1'): '0',\n",
       " ('q1', 'q2'): '0',\n",
       " ('q1', 'q1'): '1',\n",
       " ('q2', 'q2'): '0',\n",
       " ('q2', 'q1'): '1 U λ',\n",
       " ('q3', 'q3'): '0',\n",
       " ('q0', 'q2'): 'λ',\n",
       " ('q2', 'new_final'): 'λ',\n",
       " ('new_q0', 'q0'): 'λ'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ndfa.re_expressions_aux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('q0', 'q3'): '0',\n",
       " ('q0', 'q1'): '0',\n",
       " ('q1', 'q2'): '0',\n",
       " ('q1', 'q1'): '1',\n",
       " ('q2', 'q2'): '(0 U ((1 U λ).(1)*.0))',\n",
       " ('q2', 'q1'): '1 U λ',\n",
       " ('q3', 'q3'): '0',\n",
       " ('q0', 'q2'): 'λ',\n",
       " ('q2', 'new_final'): 'λ',\n",
       " ('new_q0', 'q0'): 'λ',\n",
       " ('new_q0', 'q3'): '0',\n",
       " ('new_q0', 'q1'): '0',\n",
       " ('new_q0', 'q2'): '(λ U (0.(1)*.0))',\n",
       " ('new_q0', 'new_final'): '(λ U (0.(1)*.0)).(0 U ((1 U λ).(1)*.0))*'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ndfa.re_expressions_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('new_q0', 'new_final'): '(λ U (0.(1)*.0)).(0 U ((1 U λ).(1)*.0))*'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ndfa.re_expressions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inherited methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ndfa.process_word(\"010101000\", False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.- ('q0', 'lambda')  ======> q2---- ('q2', '0')  ======> q2---- \n",
      "2.- ('q2', '1')  ======> q1---- \n",
      "3.- ('q1', '0')  ======> q2---- \n",
      "4.- ('q2', '1')  ======> q1---- \n",
      "5.- ('q1', '0')  ======> q2---- \n",
      "6.- ('q2', '1')  ======> q1---- \n",
      "7.- ('q1', '0')  ======> q2---- \n",
      "8.- ('q2', '0')  ======> q2---- \n",
      "9.- ('q2', '0')  ======> q2---- \n"
     ]
    }
   ],
   "source": [
    "ndfa.print_valid_path()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ndfa.process_word(\"\", False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('q0', 'lambda'), 'q2']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ndfa.valid_paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### re_compiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "string = \"01010100021000\" \n",
    "ans = ndfa.check_word(string, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "for i in ans:\n",
    "    print(ndfa.process_word(i, False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndfa2 = RegularExpressionGenerator(empty_symbol = \"lambda\")\n",
    "ndfa2.load_from_file(\"automaton_examples/automata4.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndfa2.convert_automaton()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('new_q0', 'new_final'): '(0*1)'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ndfa2.re_compiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('new_q0', 'new_final'): '(0)*.1'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ndfa2.re_expressions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inherited Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ndfa2.process_word(\"0000010\", False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ndfa2.process_word(\"000001\", False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.- ('q0', '0')  ======> q0---- \n",
      "2.- ('q0', '0')  ======> q0---- \n",
      "3.- ('q0', '0')  ======> q0---- \n",
      "4.- ('q0', '0')  ======> q0---- \n",
      "5.- ('q0', '0')  ======> q0---- ('q0', 'lambda')  ======> q1---- \n",
      "6.- ('q1', '1')  ======> q2---- ('q2', 'lambda')  ======> q3---- \n"
     ]
    }
   ],
   "source": [
    "ndfa2.print_valid_path()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Re_compiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01\n",
      "001\n",
      "1\n",
      "00001\n",
      "1\n",
      "0001\n",
      "1\n",
      "1\n",
      "0001\n"
     ]
    }
   ],
   "source": [
    "string = \"010011000010002100011hola2310001\" \n",
    "ans = ndfa2.check_word(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans = list(set(ans))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "for i in ans:\n",
    "    print(ndfa2.process_word(i, False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndfa3 = RegularExpressionGenerator(empty_symbol = \"lambda\")\n",
    "ndfa3.load_from_file(\"automaton_examples/automata3.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndfa3.convert_automaton()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('new_q0',\n",
       "  'new_final'): '((((0)?1*0)?(0|((1)?1*0))*)|(((0|((0)?1*))|(((0)?1*0)?(0|((1)?1*0))*((1)?1*)))(((0|0)|((0)?1*))|(((0)?1*0)?(0|((1)?1*0))*((1)?1*)))*(((0)?1*0)?(0|((1)?1*0))*)))'}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ndfa3.re_compiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('new_q0',\n",
       "  'new_final'): '((λ U ((0 U λ).(1)*.0)).(0 U ((1 U λ).(1)*.0))* U (((0 U ((0 U λ).(1)*.λ)) U ((λ U ((0 U λ).(1)*.0)).(0 U ((1 U λ).(1)*.0))*.(1 U λ).(1)*)).(((0 U λ.0) U ((0 U λ).(1)*.λ)) U ((λ U ((0 U λ).(1)*.0)).(0 U ((1 U λ).(1)*.0))*.(1 U λ).(1)*))*.(λ U ((0 U λ).(1)*.0)).(0 U ((1 U λ).(1)*.0))*))'}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ndfa3.re_expressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ndfa3.process_word(\"01\", False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0100110\n",
      "\n",
      "100\n",
      "\n",
      "11\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "1000\n",
      "\n",
      "1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "string = \"0100110210011hola2310001\" \n",
    "ans = ndfa3.check_word(string, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans = list(set(ans))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['', '0100110', '100', '1', '11', '1000']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "for i in ans:\n",
    "    print(ndfa3.process_word(i, False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note: perpahs is weird that an empty string is part of the language, but it is you can check the automata and see there is empty transictions from the initial state to the final state "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndfa4 = RegularExpressionGenerator(empty_symbol = \"lambda\")\n",
    "ndfa4.load_from_file(\"automaton_examples/automata1.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndfa4.convert_automaton()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('new_q0',\n",
       "  'new_final'): '(((0|1)1*1)|((1|((0|1)1*(0|1)))((1)?|(01*(0|1)))*(0|(01*1))))'}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ndfa4.re_compiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('new_q0',\n",
       "  'new_final'): '((0 U 1).(1)*.1 U ((1 U ((0 U 1).(1)*.(0 U 1))).(1 U λ U (0.(1)*.(0 U 1)))*.(0 U (0.(1)*.1))))'}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ndfa4.re_expressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ndfa4.process_word(\"10101\", False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01\n",
      "00110\n",
      "000\n",
      "10\n",
      "10\n",
      "011\n",
      "10\n",
      "01\n"
     ]
    }
   ],
   "source": [
    "string = \"010011000010002100011hola2310001\" \n",
    "ans = ndfa4.check_word(string, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "for i in list(set(ans)):\n",
    "    print(ndfa4.process_word(i, False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multiple final states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndfa5 = RegularExpressionGenerator(empty_symbol = \"lambda\")\n",
    "ndfa5.load_from_file(\"automaton_examples/automata5.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['q2', 'q3']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ndfa5.f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndfa5.convert_automaton()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('new_q0',\n",
       "  'new_final'): '(((b|((a|b)b*(a|b)))((b)?|(ab*(a|b)))*)|(((a|b)b*b)|((b|((a|b)b*(a|b)))((b)?|(ab*(a|b)))*(a|(ab*b)))))'}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ndfa5.re_compiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('new_q0',\n",
       "  'new_final'): '((b U ((a U b).(b)*.(a U b))).(b U λ U (a.(b)*.(a U b)))* U ((a U b).(b)*.b U ((b U ((a U b).(b)*.(a U b))).(b U λ U (a.(b)*.(a U b)))*.(a U (a.(b)*.b)))).λ)'}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ndfa5.re_expressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ndfa5.process_word(\"aaaa\", False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.- ('q0', 'a')  ======> q1---- \n",
      "2.- ('q1', 'a')  ======> q2---- \n",
      "3.- ('q2', 'a')  ======> q1---- \n",
      "4.- ('q1', 'a')  ======> q2---- \n",
      "5.- ('q2', 'b')  ======> q2---- \n",
      "6.- ('q2', 'a')  ======> q1---- \n",
      "7.- ('q1', 'b')  ======> q2---- \n",
      "8.- ('q2', 'b')  ======> q2---- \n",
      "9.- ('q2', 'b')  ======> q2---- \n",
      "10.- ('q2', 'a')  ======> q1---- \n",
      "11.- ('q1', 'a')  ======> q2---- \n",
      "12.- ('q2', 'a')  ======> q3---- \n"
     ]
    }
   ],
   "source": [
    "ndfa5.print_valid_path()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aa\n",
      "aa\n",
      "aa\n",
      "aab\n",
      "abab\n",
      "abbbba\n"
     ]
    }
   ],
   "source": [
    "string = \"aaaaaaaababababbbbaa\" \n",
    "ans = ndfa5.check_word(string, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "for i in list(set(ans)):\n",
    "    print(ndfa5.process_word(i, False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Nota: Profe en este problema nos dimos cuenta de algo, en la biblioteca al usar | que es un o, no siempre se encuentran todos los patrones, por ejemplo, en este problema los impares excepto 1 deben ser aceptados, como 3, 5, y así, pero solo encuentra los pares, y los separa de 2 en dos, porque el lado izquierdo del | hace match con los pares, y la biblioteca re al encontrar el patrón en la izquierda ya no prueba el de la derecha, entonces son cosas que pueden afectar este código, y la verdad no encontré solución, si pudiera decirme la solución se lo agredecería :). Abajo está el como hace match con los impares porque en el | intercambie los lados, pero ahora los pares después del 3 no aparecen y en impares solo aperecen de 3 en 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_patterns(pattern, string):\n",
    "    match = re.findall(pattern, string)\n",
    "    for match in re.finditer(pattern, string):\n",
    "        print(match.group())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aaa\n"
     ]
    }
   ],
   "source": [
    "pattern = \"((((a|b)(b)*b)|((b|((a|b)(b)*(a|b)))((b)?|(a(b)*(a|b)))*(a|(a(b)*b))))|((b|((a|b)(b)*(a|b)))((b)?|(a(b)*(a|b)))*))\" \n",
    "string = \"aaaa\"\n",
    "match_patterns(pattern, string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aaa\n",
      "aa\n"
     ]
    }
   ],
   "source": [
    "pattern = \"((((a|b)(b)*b)|((b|((a|b)(b)*(a|b)))((b)?|(a(b)*(a|b)))*(a|(a(b)*b))))|((b|((a|b)(b)*(a|b)))((b)?|(a(b)*(a|b)))*))\" \n",
    "string = \"aaaaa\"\n",
    "match_patterns(pattern, string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndfa6 = RegularExpressionGenerator(empty_symbol = \"epsilon\")\n",
    "ndfa6.load_from_file(\"automaton_examples/automata2.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndfa6.convert_automaton()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ndfa6.re_compiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ndfa6.re_expressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ndfa6.process_word(\"aba\", False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "This automata its final states are not reacheable, so there is not a regular expression",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-9e1a9cb337e5>\u001b[0m in \u001b[0;36mcheck_word\u001b[1;34m(self, string, printing)\u001b[0m\n\u001b[0;32m    525\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 526\u001b[1;33m                 \u001b[0mpattern\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mre_compiler\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'new_q0'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'new_final'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    527\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: ('new_q0', 'new_final')",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-60-5fddec389b60>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mstring\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"010011000010002100011hola2310001\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mans\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mndfa6\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_word\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-2-9e1a9cb337e5>\u001b[0m in \u001b[0;36mcheck_word\u001b[1;34m(self, string, printing)\u001b[0m\n\u001b[0;32m    527\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    528\u001b[0m             \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 529\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"This automata its final states are not reacheable, so there is not a regular expression\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    530\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m             \u001b[0mmatch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfindall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mException\u001b[0m: This automata its final states are not reacheable, so there is not a regular expression"
     ]
    }
   ],
   "source": [
    "string = \"010011000010002100011hola2310001\" \n",
    "ans = ndfa6.check_word(string, False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
